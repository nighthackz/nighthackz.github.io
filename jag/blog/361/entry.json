{
  "date" : 1296547200000,
  "title" : "Equations and Methods",
  "body" : "<blockquote>\n  Instead of my usual whining, I thought I'd write a few blog\n  entries that are more technical. I've been playing with a lot of\n  stuff lately. Lots of threads of ideas to play with. Mostly just\n  fragments, not adding up to much. This is the start of one thread\n  that's been wandering through my head for years. I'll need to add\n  several more blog entries before this one even starts to make\n  sense.\n</blockquote>Ignore computer science for a moment, including\neverything you know about programming languages. Think back to the\nmath courses you took in school. There are many things in that\nspace that are programming-language-ish, but missing from\nprogramming languages. Consider Newton's Method: \n\n<blockquote>\n  <h2><a href=\n  \"http://en.wikipedia.org/wiki/Newton's_method\">Newton's\n  method</a>, from Wikipedia:</h2>\n  In <a href=\"http://en.wikipedia.org/wiki/Numerical_analysis\"\n  title=\"Numerical analysis\">numerical analysis</a>, <b>Newton's\n  method</b> (also known as the <b>Newton-Raphson method</b>),\n  named after <a href=\"http://en.wikipedia.org/wiki/Isaac_Newton\"\n  title=\"Isaac Newton\">Isaac Newton</a> and <a href=\n  \"http://en.wikipedia.org/wiki/Joseph_Raphson\" title=\n  \"Joseph Raphson\">Joseph Raphson</a>, is a method for finding\n  successively better approximations to the zeroes (or <a href=\n  \"http://en.wikipedia.org/wiki/Root_of_a_function\" title=\n  \"Root of a function\">roots</a>) of a <a href=\n  \"http://en.wikipedia.org/wiki/Real_number\" title=\n  \"Real number\">real</a>-valued <a href=\n  \"http://nighthacks.com/wiki/Function_(mathematics)\" title=\n  \"Function (mathematics)\">function</a>. The algorithm is first in\n  the class of <a href=\n  \"http://en.wikipedia.org/wiki/Householder%27s_method\" title=\n  \"Householder's method\">Householder's methods</a>, succeeded by <a\n  href=\"http://en.wikipedia.org/wiki/Halley%27s_method\" title=\n  \"Halley's method\">Halley's method</a>.<br>\n  <br>\n   \n\n  <p style=\"font-weight: bold\">The Newton-Raphson method in one\n  variable:</p>\n\n  <p>Given a function <i>&#402;</i>(<i>x</i>) and its <a href=\n  \"http://en.wikipedia.org/wiki/Derivative\" title=\n  \"Derivative\">derivative</a> <i>&#402;</i>'(<i>x</i>), we begin\n  with a first guess <i>x</i><sub>0</sub>. Provided the function is\n  reasonably well-behaved a better approximation\n  <i>x</i><sub>1</sub> is</p>\n\n  <p>Geometrically, x<sub>1</sub> is the intersection point of the\n  <a href=\"http://en.wikipedia.org/wiki/Tangent_line\" title=\n  \"Tangent line\" class=\"mw-redirect\">tangent line</a> to the graph\n  of f, with the x-axis. The process is repeated until a\n  sufficiently accurate value is reached:</p>\n</blockquote>So what is Newton's Method? It's kind of like a\nfunction that takes two functions as parameters (f(x) and f'(x)).\nBut the second parameter is should really be derived from the\nfirst. f'(x) can be approximated by a little numerical trickery,\nbut it's a numerically dicey thing to do. One of the big drawbacks\nwith closures and function pointers is that you just get to execute\nthe function. You can't do any introspection. This is one of those\ntimes where I miss Lisp macros: the ability to rip open a function\nand do wild things like symbolic differentiation was wonderful. My\nPhD thesis project was filled with such hackery. \n\n<p>Instead, people rarely code Newton's method in the abstract.\nThey usually apply it on paper to some concrete function, like\nf(x)=x<sup>2</sup>-V (finding the zeros computes sqrt(V)). The code\nyou end up with looks like this:</p>\n\n<table align=\"center\">\n  <tr>\n    <td>\n<pre>\npublic double xyzzy(final double v) {\n        long lt = Double.doubleToRawLongBits(v);\n        double t = Double.longBitsToDouble((((1L&lt;&lt;52)-1)|(1L&lt;&lt;63)) &amp; lt |\n                  (((long)((((int)((lt&gt;&gt;52)&amp;((1&lt;&lt;11)-1))-1023)&gt;&gt;1)+1023))&lt;&lt;52));\n        t = 0.5*(t+v/t);\n        t = 0.5*(t+v/t);\n        t = 0.5*(t+v/t);\n        t = 0.5*(t+v/t);\n        t = 0.5*(t+v/t);\n        return t;\n }\n</pre>\n    </td>\n  </tr>\n</table>(This actually works, it's almost good to the last bit) If\nsomeone emailed this code fragment to you, I'll bet that you'd be\nhard pressed to figure out what it does. The 5x loop unrolling\nmight be a good hint, but the long bit-bashing expression at the\nbeginning is pretty opaque. Both f(x) and Newton's method have\nbecome totally obscure. The code is hard to fix or modify. It's\nvery brittle. \n\n<p>This isn't just a specific rant about Newton's method. There are\nlots of other \"method\"s that map from some problem to a piece of\ncode for computing the result. The domains that are particularly\nproblematic these days are the zillion techniques for using\nmulticore machines and clusters of them to solve some problem.\nStraightforward solutions get twisted and pulled as they're mapped\nto frameworks like MPI or Hadoop until they're totally obscure and\nwound into a ton of boilerplate.</p>\n\n<p>More on this another day...</p>\n\n",
  "images" : [ {
    "image" : "35b501243f57758c02dd9b0ce68b809a.png",
    "href" : null,
    "align" : null,
    "width" : 147,
    "height" : 48
  }, {
    "image" : "e3ed0ed85e155f78e3b1ccee03d190fe.png",
    "href" : null,
    "align" : null,
    "width" : 170,
    "height" : 48
  } ]
}